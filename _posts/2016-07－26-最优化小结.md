---
layout: post
title:  最优化方法小结
date:   2016-07-26 11:40:18 +0800
categories: machine learning
tags: 最优化
author: EthanCao
---

* content
{:toc}






最优化方法是一种求解的手段。

在机器学习中，通常给定一个模型和观察数据，此时模型的参数是未知的，因此我们的目的是通过观察数据得出模型参数，也就是训练过程。那么怎么通过观察数据拟合模型参数呢？通常可以定义模型的似然函数、损失函数或是能量系统的能量函数，它们分别从不同角度考虑拟合，但目的都是一样的，即寻找极值点，此时最优化就是一种求解的手段。

> 似然函数通常由最大似然（MLE）和最大后验（MAP），前者是最大化条件概率$P(x|\theta)$，物理解释是求解这样一组参数$\theta$，使得观察数据$x$出现的概率最大，因为目标是衡量模型和数据的相似程度，所以叫最大似然估计；后者实际上是最大化参数的后验概率$P(\theta|x)$，物理解释是观察数据通常与真实分布有误差，并且我们对模型的分布有先验知识，所以期望用先验分布$p(\theta)$来弥补数据$x$的不足，即
>
> $$p(\theta|x)=\frac{p(x|\theta)p(\theta)}{p(x)}\propto p(x|\theta)p(\theta)$$
>
> 这里我们用到了观察数据的分布$p(x)$通常为常数。
>
> 以上属于判别模型，特别的还有一类生成模型可能考虑数据与模型参数之间可能含有隐变量，因此直接定义联合分布$p(x,z|\theta)$，那么$z$其实也是未知的，需要估计。那么这时可以直接使用最优化方法求解，也可以通过求得边缘分布$p(x|\theta)=\sum_z p(x,z|\theta)$，将问题转化为最大似然估计。
>
> 损失函数和能量函数则根据模型目标来定义，比如误差函数的p范数，负log似然函数等。比如最小二乘就是使用误差函数进行参数估计的，它实际上和高斯模型下的最大似然估计结果一致。

有了需要求极值的目标函数，接下来就是使用最优化方法来求解了。

首先形式化的定义下最优化的数学模型：

$$\min f(x) \\s.t. g_i(x)\geq 0,i=1,\dots,m.—不等式约束 \\h_j(x)=0,j=1,\dots,l.—等式约束$$

##### 分类：

1. 根据目标函数和约束函数类型，可分为线性规划和非线性规划。只要有一个函数为非线性，即为非线性规划；
2. 根据约束的不同，可分为有约束和无约束的优化问题。

##### 求解方法：

1. 线性规划可以用单纯性法来求解，非线性规划可以转化为线性规划在求解；
2. 非线性规划：通过极值点的充分必要条件，求解满足这些条件的点为极值点。但有时函数特别复杂，无法直接对条件求解。此时可以使用变分法对目标函数近似，简化求解条件，再进行求解；或者使用梯度下降、EM和采样方法近似求解。

##### 非线性条件：

1. 一阶无约束：若$f(x)$在$x_0$处可微，则梯度$\Delta f(x)＝0$是$x_0$为局部极小值的必要条件；
2. 二阶无约束：若$f(x)$在$x_0$处二次可微，则梯度$\Delta f(x_0)＝0$并且Hessian矩阵$\Delta^2 f(x_0)＝0$半正定是$x_0$为局部极小值的必要条件；梯度$\Delta f(x_0)＝0$并且Hessian矩阵$\Delta^2 f(x_0)＝0$正定是$x_0$为局部极小值的充分条件；若$f(x)$为可微凸函数，则梯度$\Delta f(x_0)＝0$是$x_0$为整体极小值的充要条件。
3. 等式约束：lagrange乘子法。lagrange函数$\mathcal{L}(x,\lambda)=f(x)-\sum_j\lambda_ih_j(x)$需要满足：(i)梯度为0；(ii)$\lambda_i\neq 0$;
4. 不等式约束：kkt条件。泛化的lagrange函数$\mathcal{L}(x,\lambda,\mu)=f(x)-\sum_i\mu_ig(x)-\sum_j\lambda_jh_j(x)$必须满足：(i)梯度为0；(ii)$\lambda_i\neq 0$;(iii)$\mu_i\geq 0$;注意还要满足原来的约束条件；
5. 对偶：定义对偶函数$\theta(\mu,\lambda)=\inf\{\mathcal{L}(x,\lambda,\mu)|x \in D\}$,则对于凸规划，最小化原问题等于最大化对偶问题。简单来说，$f(x)\geq \theta(w,v)$。


总的来说，我们其实只会解线性规划和非线性规划的无约束问题，对于有约束我们通过定义lagrange函数转化为无约束问题。若还是太复杂，则试试对偶问题。

然而，有时模型的设置仍然太复杂，我们就期望使用近似的方法求解。或者对于没有封闭解的情况，使用梯度下降迭代求解。接下来我们分别介绍变分法可以将复杂的函数近似为简单的函数，然后介绍具体优化的方法EM和采样。最后介绍多种梯度下降的方法。

##### 变分法

变分法是可以对没有具体形式或形式很复杂的函数求解近似简单函数的方法。具体可以看[pengTitus](http://list.youku.com/albumlist/show?id=3744431&ascending=1&page=1)老师的视频。

具体应用到机器学习领域则为变分推断，可以参考PRML第十章以及Blei大神在lda中的证明，比如这篇[博客](http://www.myexception.cn/other/1939443.html)。和Blei大神的课件Variational Inference。

还有另外一类叫做变分贝叶斯推断，可以参考A Tutorial on Variational Bayesian Inference。

##### EM

参考PRML第九章。

##### 采样

直接变换

拒绝采样

重要性采样

针对怎么取q(z)，下一步的节点由上一步节点来确定。

LDA数学八卦

### 梯度下降

所谓梯度下降，就是自变量沿着某一方向移动，使得函数值不断变小，直至停止。比如一元函数中，x可以向左或向右。但到了多元函数，方向就变得复杂了，比如可以固定其他自变量，只移动其中一维。所以，梯度下降中最重要的两个问题就是寻找合适的方向，以及移动的步长。

形式化定义即是：

$$\theta_{k+1}=\theta_k+\alpha d_k$$

不断重复直至收敛。其中$d_k$为方向，$\alpha$为步长。

梯度下降通常使用在不能求出解析解时，给出数值解，但是不能保证全局最优解，容易陷入局部极小值点。接下来从分别从两个方面介绍几种常用的梯度下降方法。

#### 寻找步长

先来看步长，其实也就是算法的学习率$\alpha$。

##### 固定学习率：

最常用，有些情况不理想。

##### 动态学习率

1. 逐渐减小学习率，就是在越接近“山谷”的地方，使用越小的学习率，防止一下子迈过了。
2. 斜率大的时候使用较小的学习率；斜率小的时候使用较大的学习率。（？）

事实上，目标函数$f(\theta_{k+1})=f(\theta_k+\alpha d_k)$可以看成$\alpha$的函数$h(\alpha)$，问题转化成求$\alpha>0$时的最小值。如果可导，即是$\Delta h(\alpha)=\Delta f(\theta_k+\alpha d_k)d_k＝0$。

还可以用一些搜索方法可以加速这一过程。

1. 线性搜索：比如二分搜索；
2. 回溯线性搜索：先沿着搜索方向移动较大步长，然后逐步缩小直至满足Armijo条件。
3. 二次插值法：构造二次函数，估计函数的极值点。

还有一些wolfe搜索，Armijo搜索以及Goldstein条件等非精确搜索的方法再此不赘述。

##### 最速下降法

顾名思义，取函数值下降最快的方向作为下降方向，即负梯度$d_k=-\Delta f(x_k)$。

为什么最快呢？

将目标函数在当前点泰勒展开：$f(\theta_k+\alpha d_k)=f(\theta_k)+\alpha d_k\Delta f(\theta_k)+o(\alpha d_k)$

忽略高阶无穷小，由于步长大于0，所以$d_k \Delta f(\theta_k)<0$能使得函数值下降。

根据柯西不等式：$|d_k \Delta f|\leq|d_k||\Delta f|$

当且仅当$d_k=-\Delta f$时，$d_k \Delta f$最小，函数下降量最大。

缺点：事实上，每次的下降方向时局部最快，从全局来讲通常很慢。

来看一个例子。 

函数$f(x,y)$的图像如图所示，纵轴代表函数值。

![2](fig/2.jpg)

它在二维平面的等高线如图所示。

![1](fig/1.jpg)

我们运行最速下降，可以看到(i)多个极值点，根据初始值不同，随机寻找一个；(ii)等值线接近圆形，下降较快，椭圆则较慢。 这是因为寻优过程总是呈锯齿状。根据最优步长公式：$\Delta f(\theta_{k+1})d_k=-d_{k+1}d_k=0$

典型例子：logistic回归。$$\theta_{k+1}=\theta_k+\sum_i\alpha(y^{(i)}-h_\theta(x^{(i)}))x_k^{(i)}$$

#####批梯度下降

如上述的回归例子所示，每一次需要遍历所有样本，才更新参数，这种方法就是批梯度下降。

##### 随机梯度下降

批梯度下降在样本量很大的情况下显然很耗时，此时可以使用随机梯度下降。即每一次更新只使用了一个训练样本，但更新了m次。

##### 牛顿法

刚才讨论了最速方向其实只用了函数的一阶导数信息，牛顿法则是可以考虑函数的二阶信息。这样做的好处在于收敛速度更快，因为是二阶收敛。形象一点的解释是一阶导数考虑当前坡度是否够大，而二阶导数还考虑走了这一步之后，坡度是否变的更大。尤其对于上面提到的椭圆慢的问题，有较好的效果。如下图，红色是牛顿法，绿色是最速法的迭代路径。

 ![3](fig/3.jpg)

具体算法：

对目标函数进行二阶泰勒展开：

$$f(\theta)=f(\theta_k)+\Delta f(\theta_k)(\theta-\theta_k)+\frac{1}{2}(\theta-\theta_k)\Delta^2f(\theta)(\theta-\theta_k)$$

注：以下我们使用$f_k=f(\theta_k)$方便书写。设$g_k=\Delta f_k, G_k=\Delta^2 f_k$。

回忆在二阶无约束最优化的条件是一阶导数为0，并且hessian矩阵正定。

首先我们对$f'(\theta)=g_k+G_k(\theta-\theta_k)=0$，若$G_k$非奇异，则整理可得：

$$\theta=\theta_k-G_k^{-1}g_k$$

这个式子可以看成下降方向为$d_k=-G_k^{-1}g_k$，步长$\alpha=1$.

我们也可以通过求解方程组$G_kd=-g_k$得到方向$d_k$.

##### 阻尼牛顿法

由于牛顿法步长为定值1，所以有可能出现函数值上升，甚至迭代点发散的情况。

因此提出阻尼牛顿法，添加步长因子：

$$\theta=\theta_k-\alpha G_k^{-1}g_k$$

##### 拟牛顿条件

牛顿法虽然收敛快，但是需要计算二阶偏导数，计算量大，而且有时不能保证hessian矩阵正定，从而牛顿法失效。为了克服这个问题，提出拟牛顿法。

拟牛顿法的基本思想是不用二阶偏导数而构造出可以近似hessian矩阵的正定对称阵，在拟牛顿的条件下优化目标函数。

首先假设$B\approx G, D\approx G^{-1}$,对于$f(\theta)$在$\theta_{k+1}$处的二阶泰勒展开，我们取$\theta=\theta_k$，有：

$$g_{k+1}-g_k=G_{k+1}(\theta_{k+1}-\theta_k)$$

或者

$$y_k=B_{k+1}x_k, x_k=D_{k+1}y_k$$，其中$y_k,x_k$为引入记号。

这就叫做拟牛顿条件。接下来我们介绍几种常见的拟牛顿方法

##### DFP

DFP的核心思想是通过迭代的方法对$G^{-1}$做近似。

$$D_{k+1}=D_k+\Delta D_k$$

其中$D_0$通常取单位矩阵$I$，关键是$\Delta D$如何构造。不妨设$\Delta D_k=\alpha uu^T+\beta vv^T$.

整理得：$x_k=D_ky_k+u(\alpha u^Ty_k)+v(\beta v^Ty_k)$

令括号中分别等于1和－1.并且通过再整理得$u-v=x_k-D_ky_k$.

再令$u=x_k,v=D_ky_k$.得到矫正矩阵：

$$\Delta D_k=\frac{x_kx_k^T}{x_k^Ty_k}-\frac{D_ky_ky_k^TD_k}{y_k^TD_ky_k}$$

##### BFGS

BFGS与DFP推导完全类似，只是利用$B_k$直接逼近hessian矩阵$G$，但是性能更好，是最为常用的梯度下降方法。为什么性能更好呢？进一步的研究证明有时DFP有时数值上不稳定，甚至会产生奇异的hessian矩阵近似。

更新矩阵为，实际上只是D和B互换，x和y互换：

$$\Delta B_k=\frac{y_ky_k^T}{y_k^Tx_k}-\frac{B_kx_kx_k^TB_k}{x_k^TB_kx_k}$$

回想一下在求下降方向时，我们需要得到$G_k^{-1}$，因此，我们利用sherman－morrison公式直接得到$B^{-1}$的更新公式：

$$B^{-1}_{k+1}=(I-\frac{x_ky_k^T}{y_k^Tx_k})B_k^{-1}(I-\frac{y_kx_k^T}{x_ky_k^T})+\frac{x_kx_k^T}{y_k^Tx_k}$$

##### L-BFGS

L-BFGS(Limited-memory BFGS)实际上是针对BFGS需要存储$N\times N$矩阵$B_k^{-1}$，在内存上开销很大而做的优化。

其基本思想是不再存储完整的$B_k^{-1}$，而是存储序列$\{x_i\},\{y_i\}$，甚至对于这两个响亮序列也不是全都存储，而是存储最新的m个，这样我们的存储由原来的$O(N^2)$降低到了$O(mN)$.

不妨设$\rho_k=\frac{1}{y_k^Tx_k},V_k=I-\rho_ky_kx_k^T$，于是$B_k^{-1}$的更新公式为：

$$B_{k+1}^{-1}=V_k^TB_k^{-1}V_k+\rho_kx_kx_k^T$$

由此可见，计算$B_k^{-1}$需要用到$\{x_i,y_i\}_{i=0}^k$，自然的，我们只保留最近的m组。这样就只能近似计算。但是即使近似计算公式也很复杂。索性我们只需要计算$B_k^{-1}g_k$得到下降方向，这里已经有人给出快速计算的方法。

 ![4](fig/4.png)

详细证明过程可以参考文献[3].

##### 共轭方向法

上面的方法，前、后两次迭代的方向并没有特别的相关要求。共轭梯度法就是要求新的搜索方向与前面所有的搜索方向是共轭的。即

$$d_mGd_n=0$$

其中G为对称正定矩阵，$m\neq n$为两个搜索方向。

这样做的好处是可以更快的收敛，因为尽量不浪费之前的搜索。假设沿着一系列的共轭方向做迭代（寻找极小值点），这些共轭方向组成的集合叫作共轭方向集，则沿共轭方向集的每个方向顺序做line search的时候，在每个方向上都不需要做重复搜索——在任何一个方向上的移动，都不会影响到在另一个方向上已经找到的极小值。拿一个在水平面上走路的例子来做比喻：你在水平方向A上走了10米，然后再沿着与水平方向垂直的另一个方向B上又走了10米，那么，你在方向A上走动的时候，在方向B上的坐标是不变的；你在方向B上走动的时候，在方向A上的坐标也是不变的。因此，把方向A和方向B看作两个共轭方向，那么，你在这两个共轭方向中的任何一个方向上移动，都不会影响到另一个方向上已经走到的坐标（把它想像成在这个方向上的极小值）。

具体的性质已经有人证明，被称为二次终止性。当目标函数是二次函数$f(x)=\frac{1}{2}x^TGx+b^Tx+c$,共轭方向法最多经过N步（N为向量维数）迭代，就可以到达极小值点——这种特性又叫作二次收敛性（Quadratic Convergence）。

理论与实践证明，将二次收敛算法用于非二次的目标函数，亦有很好的效果，但迭代次数不一定保证有限次，即对非二次n维目标函数经n步共轭方向一维搜索不一定就能达到极小点。在这种情况下，为了找到极小点，可用泰勒级数将该函数在极小点附近展开，略去高于二次的项之后即可得该函数的二次近似。实际上很多的函数都可以用二次函数很好地近似，甚至在离极小点不是很近的点也是这样。故用二次函数近似代替非二次函数来处理的方法不仅在理论分析上是重要的，而且在工程实际应用中也是可取的。

我们先来看一个典型的共轭方向法：

##### Powell方法

Powell方法是一种有效的直接搜索法，本质上是共轭方向法。

它把整个计算过程分成若干个阶段，每个阶段由n＋1次一维搜索组成。在每一阶段中，先依次沿着已知的n个方向搜索，得到一个最好点，然后沿着本阶段的初点与该最好点的连线方向进行搜索，求得这一阶段的最好点。在用最后的搜索方向取代前n个方向之一，开始下一阶段的迭代。具体如下：

1. 给定初始点$x^{(0)}$，n个线性无关的方向$d^{(1,1)},\cdots,d^{(1,n)}$，通常直接去单位矩阵的n个列向量；
2. 从k＝1开始，令$x^{(k,0)}=x^{(k-1)}$，从$x^{(k,0)}$出发，依次沿方向$d^{(k,1)},\cdots,d^{(k,n)}$进行搜索，得到点$x^{(k,1)},\cdots,x^{(k,n)}$，再从$x^{(k,n)}$出发，沿着$d^{(k,n+1)}=x^{(k,n)}-x^{(k,0)}$搜索，得到$x^{(k)}$；
3. 若$||x^{(k)}-x^{(k-1)}||<\epsilon$，则停止；否则，令$d^{(k+1,j)}=d^{(k,j+1)},j=1,\cdots,n.$，令$k:=k+1$，返回步骤2。

出自《最优化理论与算法》陈宝林P349。例子和证明都在书中。

##### 共轭梯度法

共轭梯度法的基本思想是把共轭性与最速下降相结合，利用已知点处的梯度构造一组共轭方向，并沿着这组方向进行搜索，求出目标函数的极小点。

说白了，就是用当前点的负梯度方向，与前面的搜索方向进行共轭化，以得到新的搜索方向。

计算过程也很简单。以FR算法为例：

1. 给定初始点$x^{(1)}$，允许误差$\epsilon>0$，令$y^{(1)}=x^{(1)},d^{(1)}=-\Delta f(y^{(1)}),k=j=1.$;
2. 若$||\Delta f(y^{(j)})<\epsilon||$，则停止计算；否则，作一维搜索，求$\lambda_j$，满足：$min_{\lambda\geq0}f(y^{(j)}+\lambda_jd^{(j)})$.则$y^{(j+1)}=y^{(j)}+\lambda_jd^{(j)}$;
3. 如果$j<n$，则进行步骤4；否则，步骤5；
4. 令$d^{(j+1)}=-\Delta f(y^{(j+1)})+\beta_jd^{(j)}$，其中$\beta_j=\frac{||\Delta f(y^{(j+1)})||^2}{||\Delta f(y^{(j)})||^2}$,令$j:=j+1$,转步骤2；
5. 令$x^{(k+1)}=y^{(n+1)},y^{(1)}=x^{(k+1)},d^{(1)}=-\Delta f(y^{(1)})$，令$j=1,k:=k+1$，转步骤2。

明显步骤4即是根据当前最速下降方向构造共轭方向，然后寻找当前迭代的最优点。

事实上，$\beta_j$还有很多表示方式，比如PRP等。这些均采用精确的一维搜索，即步骤2中求$\lambda$。这样需要付出很大代价，因此许多情形下采用不精确的一维搜索。这样又可能出现搜索方向不是下降方向。解决办法就是以最速方向重新开始。然而，这样做可能会降低计算效率。还有其他方法不再赘述。

共轭梯度方法的另一个关键在于$\beta$的取值，这里其实做了一个假设，即下一步的共轭搜索方向由当前梯度和上一步的搜索方向线性组合而成，并且满足共轭条件。就是令步骤4中两端左乘$d^{(k)T}G$后等于0，然后解得$\beta$。

参考：

1. http://www.codelast.com/；
2. http://blog.csdn.net/itplus/article/details/21896981
3. Nocedal J. Updating quasi-Newton matrices with limited storage[J]. Mathematics of computation, 1980, 35(151): 773-782.

